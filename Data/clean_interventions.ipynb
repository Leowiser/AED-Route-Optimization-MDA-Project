{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge and clean different interventions files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from owslib.wfs import WebFeatureService\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import mapclassify\n",
    "from shapely.geometry import Point\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ambulance          = pd.read_parquet('ambulance_locations.parquet.gzip', engine='pyarrow')\n",
    "# mug                = pd.read_parquet('mug_locations.parquet.gzip', engine='pyarrow')\n",
    "# pit                = pd.read_parquet('pit_locations.parquet.gzip', engine='pyarrow')\n",
    "# aed                = pd.read_parquet('aed_locations.parquet.gzip', engine='pyarrow')\n",
    "cad9               = pd.read_parquet('cad9.parquet.gzip', engine='pyarrow')\n",
    "interventions_bxl  = pd.read_parquet('interventions_bxl.parquet.gzip', engine='pyarrow')\n",
    "interventions_bxl2 = pd.read_parquet('interventions_bxl2.parquet.gzip', engine='pyarrow')\n",
    "interventions1     = pd.read_parquet('interventions1.parquet.gzip', engine='pyarrow')\n",
    "interventions2     = pd.read_parquet('interventions2.parquet.gzip', engine='pyarrow')\n",
    "interventions3     = pd.read_parquet('interventions3.parquet.gzip', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning, appending interventions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cad9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we decided not to use (poor quality/not present in other files etc.)\n",
    "cad9.drop(columns=['province', 'Service Name', 'Permanence short name', 'Permanence long name', 'EventSubType Trip',\n",
    "                   'EventLevel Trip', 'CitysectionName intervention', 'T1confirmed', 'Intervention time (T1Confirmed)', \n",
    "                   'Departure time (T1Confirmed)', 'UI', 'ID', 'MISSION_NR', 'AMBUCODE', 'UNIT_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming remaining column names\n",
    "cad9.rename(columns={'Mission ID': 'mission_id',\n",
    "                   'Latitude permanence': 'latitude_permanence',\n",
    "                   'Longitude permanence': 'longitude_permanence',\n",
    "                   'Vector Type': 'vector_type',\n",
    "                   'EventType Trip': 'eventtype_trip',\n",
    "                   'CityName intervention': 'cityname_intervention',\n",
    "                   'Latitude intervention': 'latitude_intervention',\n",
    "                   'Longitude intervention': 'longitude_intervention',\n",
    "                   'Province invervention': 'province_intervention',\n",
    "                   'T0': 't0',\n",
    "                   'T1': 't1',\n",
    "                   'T2': 't2',\n",
    "                   'T3': 't3',\n",
    "                   'T4': 't4',\n",
    "                   'T5': 't5',\n",
    "                   'T6': 't6',\n",
    "                   'T7': 't7',\n",
    "                   'Name destination hospital' : 'name_destination_hospital',\n",
    "                   'Intervention time (T1Reported)': 'intervention_time_t3t1',\n",
    "                   'Departure time (T1Reported)': 'departure_time_t1t0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column to track which file the data comes from\n",
    "cad9.insert(0, 'source', 'cad9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brussels 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we decided not to use (poor quality/not present in other files etc.)\n",
    "interventions_bxl.drop(columns=['service_name', 'housenumber_permanence', 'permanence_short_name', 'permanence_long_name', 'eventLevel_firstcall',\n",
    "                   'eventlevel_trip', 'postalcode_intervention', 't1confirmed', 't9', 'waiting_time', 'intervention_duration',\n",
    "                   'unavailable_time', 'postalcode_destination_hospital', 'cityname_destination_hospital', 'streetname_destination_hospital', \n",
    "                   'housenumber_destination_hospital', 'calculated_traveltime_departure_', 'calculated_distance_departure_to',\n",
    "                   'calculated_traveltime_destinatio', 'calculated_distance_destination_', 'number_of_transported_persons'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming remaining column names\n",
    "interventions_bxl.rename(columns={'intervention_time_t1reported': 'intervention_time_t3t1',\n",
    "                     'departure_time_t1reported': 'departure_time_t1t0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column to track which file the data comes from\n",
    "interventions_bxl.insert(0, 'source', 'interventions_bxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for province since this file doesn't have it\n",
    "interventions_bxl.insert(1, 'province_intervention', 'BXL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brussels 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we decided not to use (poor quality/not present in other files etc.)\n",
    "interventions_bxl2.drop(columns=['description_nl', 'ic_description_nl', 'creationtime', 'Number of transported persons',\n",
    "                   'Permanence long name NL', 'Permanence long name FR', 'Permanence short name NL', 'Permanence short name FR', 'Service Name NL',\n",
    "                   'Service Name FR', 'Housenumber Permanence', 'Vector type FR', 'Cityname destination hospital', \n",
    "                   'Streetname destination hospital', 'Housenumber destination hospital', 'Abandon reason FR'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean EventType and EventLevel - keep EventType only\n",
    "def process_string(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    elif '-' in x:\n",
    "        first_dash_index = x.find('-')\n",
    "        return x[:first_dash_index - 4] + x[first_dash_index:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# Apply the function to the column\n",
    "interventions_bxl2['EventType and EventLevel'] = interventions_bxl2['EventType and EventLevel'].apply(process_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract postal code and city name\n",
    "interventions_bxl2['postalcode_permanence'] = interventions_bxl2['Cityname Permanence'].str.split().str[0]\n",
    "interventions_bxl2['Cityname Permanence'] = interventions_bxl2['Cityname Permanence'].str.split().str[1:].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming remaining column names\n",
    "interventions_bxl2.rename(columns={'Mission ID': 'mission_id',\n",
    "                   'T0': 't0',\n",
    "                   'Cityname Intervention': 'cityname_intervention',\n",
    "                   'Longitude intervention': 'longitude_intervention',\n",
    "                   'Latitude intervention': 'latitude_intervention',\n",
    "                   'EventType and EventLevel': 'eventtype_firstcall',\n",
    "                   'Cityname Permanence': 'cityname_permanence',\n",
    "                   'Streetname Permanence': 'streetname_permanence',\n",
    "                   'Latitude Permanence': 'longitude_permanence',\n",
    "                   'Longitude Permanence': 'latitude_permanence',\n",
    "                   'Vector type NL': 'vector_type',\n",
    "                   'Name destination hospital': 'name_destination_hospital',\n",
    "                   'Abandon reason NL': 'abandon_reason',\n",
    "                   'T1': 't1',\n",
    "                   'T2': 't2',\n",
    "                   'T3': 't3',\n",
    "                   'T4': 't4',\n",
    "                   'T5': 't5',\n",
    "                   'T6': 't6',\n",
    "                   'T7': 't7'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column to track which file the data comes from\n",
    "interventions_bxl2.insert(0, 'source', 'interventions_bxl2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for province since this file doesn't have it\n",
    "interventions_bxl2.insert(1, 'province_intervention', 'BXL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interventions 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we decided not to use (poor quality/not present in other files etc.)\n",
    "interventions1.drop(columns=['Service Name', 'HouseNumber permanence', 'Permanence short name', 'Permanence long name', 'EventLevel Firstcall',\n",
    "                   'EventLevel Trip', 'PostalCode intervention', 'T1confirmed', 'T9', 'Intervention time (T1Confirmed)', \n",
    "                   'Departure time (T1Confirmed)', 'Unavailable time', 'PostalCode destination hospital', 'CityName destination hospital',\n",
    "                   'StreetName destination hospital', 'HouseNumber destination hospital', 'Calculated travelTime destinatio',\n",
    "                   'Calculated Distance destination', 'Number of transported persons', 'Waiting time', 'Intervention duration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming remaining column names\n",
    "interventions1.rename(columns={'Mission ID': 'mission_id',\n",
    "                               'PostalCode permanence': 'postalcode_permanence',\n",
    "                               'CityName permanence': 'cityname_permanence',\n",
    "                               'StreetName permanence': 'streetname_permanence',\n",
    "                               'Latitude permanence': 'latitude_permanence',\n",
    "                               'Longitude permanence': 'longitude_permanence',\n",
    "                               'Vector type': 'vector_type',\n",
    "                               'EventType Firstcall': 'eventtype_firstcall',\n",
    "                               'EventType Trip': 'eventtype_trip',\n",
    "                               'CityName intervention': 'cityname_intervention',\n",
    "                               'Latitude intervention': 'latitude_intervention',\n",
    "                               'Longitude intervention': 'longitude_intervention',\n",
    "                               'Province intervention': 'province_intervention',\n",
    "                               'T0': 't0',\n",
    "                               'T1': 't1',\n",
    "                               'T2': 't2',\n",
    "                               'T3': 't3',\n",
    "                               'T4': 't4',\n",
    "                               'T5': 't5',\n",
    "                               'T6': 't6',\n",
    "                               'T7': 't7',\n",
    "                               'Intervention time (T1Reported)': 'intervention_time_t3t1',\n",
    "                               'Departure time (T1Reported)': 'departure_time_t1t0',\n",
    "                               'Name destination hospital': 'name_destination_hospital',\n",
    "                               'Abandon reason': 'abandon_reason'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column to track which file the data comes from\n",
    "interventions1.insert(0, 'source', 'interventions1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interventions 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we decided not to use (poor quality/not present in other files etc.)\n",
    "interventions2.drop(columns=['Service Name', 'HouseNumber permanence', 'Permanence short name', 'Permanence long name', 'EventLevel Firstcall',\n",
    "                   'EventLevel Trip', 'PostalCode intervention', 'T1confirmed', 'T9', 'Intervention time (T1Confirmed)', \n",
    "                   'Departure time (T1Confirmed)', 'Unavailable time', 'PostalCode destination hospital', 'CityName destination hospital',\n",
    "                   'StreetName destination hospital', 'HouseNumber destination hospital', 'Calculated travelTime destinatio',\n",
    "                   'Calculated Distance destination', 'Number of transported persons', 'Waiting time', 'Intervention duration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming remaining column names\n",
    "interventions2.rename(columns={'Mission ID': 'mission_id',\n",
    "                               'PostalCode permanence': 'postalcode_permanence',\n",
    "                               'CityName permanence': 'cityname_permanence',\n",
    "                               'StreetName permanence': 'streetname_permanence',\n",
    "                               'Latitude permanence': 'latitude_permanence',\n",
    "                               'Longitude permanence': 'longitude_permanence',\n",
    "                               'Vector type': 'vector_type',\n",
    "                               'EventType Firstcall': 'eventtype_firstcall',\n",
    "                               'EventType Trip': 'eventtype_trip',\n",
    "                               'CityName intervention': 'cityname_intervention',\n",
    "                               'Latitude intervention': 'latitude_intervention',\n",
    "                               'Longitude intervention': 'longitude_intervention',\n",
    "                               'Province intervention': 'province_intervention',\n",
    "                               'T0': 't0',\n",
    "                               'T1': 't1',\n",
    "                               'T2': 't2',\n",
    "                               'T3': 't3',\n",
    "                               'T4': 't4',\n",
    "                               'T5': 't5',\n",
    "                               'T6': 't6',\n",
    "                               'T7': 't7',\n",
    "                               'Intervention time (T1Reported)': 'intervention_time_t3t1',\n",
    "                               'Departure time (T1Reported)': 'departure_time_t1t0',\n",
    "                               'Name destination hospital': 'name_destination_hospital',\n",
    "                               'Abandon reason': 'abandon_reason'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column to track which file the data comes from\n",
    "interventions2.insert(0, 'source', 'interventions2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interventions 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we decided not to use (poor quality/not present in other files etc.)\n",
    "interventions3.drop(columns=['Service Name', 'HouseNumber permanence', 'Permanence short name', 'Permanence long name', 'EventLevel Firstcall',\n",
    "                   'EventLevel Trip', 'PostalCode intervention', 'T1confirmed', 'T9', 'Intervention time (T1Confirmed)', \n",
    "                   'Departure time (T1Confirmed)', 'Unavailable time', 'PostalCode destination hospital', 'CityName destination hospital',\n",
    "                   'StreetName destination hospital', 'HouseNumber destination hospital', 'Calculated travelTime destinatio',\n",
    "                   'Calculated Distance destination', 'Number of transported persons', 'Waiting time', 'Intervention duration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming remaining column names\n",
    "interventions3.rename(columns={'Mission ID': 'mission_id',\n",
    "                               'PostalCode permanence': 'postalcode_permanence',\n",
    "                               'CityName permanence': 'cityname_permanence',\n",
    "                               'StreetName permanence': 'streetname_permanence',\n",
    "                               'Latitude permanence': 'latitude_permanence',\n",
    "                               'Longitude permanence': 'longitude_permanence',\n",
    "                               'Vector type': 'vector_type',\n",
    "                               'EventType Firstcall': 'eventtype_firstcall',\n",
    "                               'EventType Trip': 'eventtype_trip',\n",
    "                               'CityName intervention': 'cityname_intervention',\n",
    "                               'Latitude intervention': 'latitude_intervention',\n",
    "                               'Longitude intervention': 'longitude_intervention',\n",
    "                               'Province intervention': 'province_intervention',\n",
    "                               'T0': 't0',\n",
    "                               'T1': 't1',\n",
    "                               'T2': 't2',\n",
    "                               'T3': 't3',\n",
    "                               'T4': 't4',\n",
    "                               'T5': 't5',\n",
    "                               'T6': 't6',\n",
    "                               'T7': 't7',\n",
    "                               'Intervention time (T1Reported)': 'intervention_time_t3t1',\n",
    "                               'Departure time (T1Reported)': 'departure_time_t1t0',\n",
    "                               'Name destination hospital': 'name_destination_hospital',\n",
    "                               'Abandon reason': 'abandon_reason'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column to track which file the data comes from\n",
    "interventions3.insert(0, 'source', 'interventions3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append interventions, clean further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_interventions = pd.concat([interventions1, interventions2, interventions3, interventions_bxl, interventions_bxl2, cad9], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean vector_type column\n",
    "vector_type_mapping = {'Ambulance Event': 'Ambulance',\n",
    "                       'Ambulance Disaster': 'Ambulance',\n",
    "                       'MUG Event' : 'MUG',\n",
    "                       'PIT Event' : 'PIT',\n",
    "                       'Ambulance Exceptional' : 'Ambulance',\n",
    "                       'MUG Disaster' : 'MUG',\n",
    "                       'PIT Disaster' : 'PIT',\n",
    "                       'Brandziekenwagen' : 'Ambulance',\n",
    "                       'Decontanimatieziekenwagen' : 'Ambulance',\n",
    "                       'AMB' : 'Ambulance'\n",
    "                      }\n",
    "\n",
    "all_interventions['vector_type'] = all_interventions['vector_type'].replace(vector_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'eventtype' which takes the value of 'eventtype_firstcall' when it is not missing, otherwise takes 'eventtype_trip'\n",
    "all_interventions['eventtype'] = all_interventions['eventtype_firstcall'].fillna(all_interventions['eventtype_trip'])\n",
    "\n",
    "# Drop the original columns\n",
    "all_interventions = all_interventions.drop(columns=['eventtype_firstcall', 'eventtype_trip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for cardiac eventtypes\n",
    "cardiac_interventions = all_interventions[all_interventions['eventtype'].str.startswith(('P011', 'P003', 'P010',\n",
    "                                                                                                 'P029', 'P004',\n",
    "                                                                                                 'P019', 'P008',\n",
    "                                                                                                 'P014')) | all_interventions['eventtype'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant time columns\n",
    "cardiac_interventions.drop(columns=['t2', 't4', 't5', 't6', 't7'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean intervention latitudes\n",
    "# Step 1: Convert the column to string\n",
    "cardiac_interventions['latitude_intervention'] = cardiac_interventions['latitude_intervention'].astype(str)\n",
    "\n",
    "# Step 2: Remove decimal points from every value\n",
    "cardiac_interventions['latitude_intervention'] = cardiac_interventions['latitude_intervention'].str.replace('.', '')\n",
    "\n",
    "# Step 3: Add a point after every 2 characters\n",
    "cardiac_interventions['latitude_intervention'] = cardiac_interventions['latitude_intervention'].apply(lambda x: x[:2] + '.' + x[2:])\n",
    "\n",
    "# Step 4: Convert the column back to float64 data type\n",
    "cardiac_interventions['latitude_intervention'] = pd.to_numeric(cardiac_interventions['latitude_intervention'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean intervention longitudes\n",
    "# Step 1: Convert the column to string\n",
    "cardiac_interventions['longitude_intervention'] = cardiac_interventions['longitude_intervention'].astype(str)\n",
    "\n",
    "# Step 2: Remove decimal points from every value\n",
    "cardiac_interventions['longitude_intervention'] = cardiac_interventions['longitude_intervention'].str.replace('.', '')\n",
    "\n",
    "# Step 3: Add a point after every 2 characters\n",
    "cardiac_interventions['longitude_intervention'] = cardiac_interventions['longitude_intervention'].apply(lambda x: x[:1] + '.' + x[1:])\n",
    "\n",
    "# Step 4: Convert the column back to float64 data type\n",
    "cardiac_interventions['longitude_intervention'] = pd.to_numeric(cardiac_interventions['longitude_intervention'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason this is not working anymore....\n",
    "# The format of t0 and t3 is different based on the source file --> we clean this, so that every format is the same\n",
    "# def convert_datetime_t0(row):\n",
    "#     if pd.isnull(row['t0']):\n",
    "#         return None\n",
    "#     elif row['source'] == 'cad9':\n",
    "#         return pd.to_datetime(row['t0']).strftime('%Y-%m-%d %H:%M:%S')    # Convert to desired format for 'cad9'\n",
    "#     elif row['source'] == 'interventions_bxl':\n",
    "#         return pd.to_datetime(row['t0'], utc=True).strftime('%Y-%m-%d %H:%M:%S')    # Convert to desired format for 'bxl'\n",
    "#     else:\n",
    "#         return pd.to_datetime(row['t0'], format='%d%b%y:%H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')    # Convert to default format for other values (interventions1, 2, 3, bxl2)\n",
    "\n",
    "# def convert_datetime_t3(row):\n",
    "#     if pd.isnull(row['t3']):\n",
    "#         return None\n",
    "#     elif row['source'] == 'interventions_bxl':\n",
    "#         return pd.to_datetime(row['t3'], utc=True).strftime('%Y-%m-%d %H:%M:%S')    # Convert to desired format for 'bxl'\n",
    "#     elif row['source'] == 'interventions_bxl2':\n",
    "#         return pd.to_datetime(row['t3'], format='%d%b%y:%H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')    # Convert to desired format for 'bxl2'\n",
    "#     else:\n",
    "#         return pd.to_datetime(row['t3']).strftime('%Y-%m-%d %H:%M:%S')    # Convert to default format for other values (interventions1, 2, 3, cad9)\n",
    "\n",
    "# # Apply the functions to t0 and t2\n",
    "# cardiac_interventions['t0'] = cardiac_interventions.apply(convert_datetime_t0, axis=1)\n",
    "# # cardiac_interventions['t3'] = cardiac_interventions.apply(convert_datetime_t3, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure latitude and longitude are floats\n",
    "cardiac_interventions['latitude_intervention'] = cardiac_interventions['latitude_intervention'].astype(float)\n",
    "cardiac_interventions['longitude_intervention'] = cardiac_interventions['longitude_intervention'].astype(float)\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf_cardiac = gpd.GeoDataFrame(\n",
    "    cardiac_interventions,\n",
    "    geometry=[Point(lon, lat) for lon, lat in zip(cardiac_interventions['longitude_intervention'], cardiac_interventions['latitude_intervention'])],\n",
    "    crs=\"EPSG:4326\"  # Assuming WGS84 (lat/lon)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Leuven and municipalities geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the WFS service\n",
    "wfs_url = \"https://geo.api.vlaanderen.be/VRBG2019/wfs?service=WFS&version=2.0.0&request=GetFeature\"\n",
    "\n",
    "# Connect to the WFS service\n",
    "wfs = WebFeatureService(wfs_url, version='1.1.0')\n",
    "\n",
    "# List available layers\n",
    "for layer in list(wfs.contents):\n",
    "    print(layer)\n",
    "\n",
    "# Choose the desired layer\n",
    "layer_name = 'VRBG2019:Refgem'\n",
    "\n",
    "# Fetch data as a GeoDataFrame\n",
    "response = wfs.getfeature(typename=layer_name, outputFormat='json')\n",
    "\n",
    "# Load the GeoDataFrame from the WFS response\n",
    "flanders_municips_2019 = gpd.read_file(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_gdf = flanders_municips_2019[flanders_municips_2019['NISCODE'] == '24062']\n",
    "filtered_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filtered GDF CRS:\", filtered_gdf.crs)\n",
    "print(\"GDF Cardiac CRS:\", gdf_cardiac.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cardiac = gdf_cardiac.to_crs(filtered_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform spatial join to keep only points within the 'filtered_gdf' geometries\n",
    "filtered_cardiac_interventions = gdf_cardiac[gdf_cardiac.geometry.within(filtered_gdf.union_all())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "filtered_gdf.plot(ax=ax, color='lightblue', edgecolor='black', alpha=0.5)\n",
    "filtered_cardiac_interventions.plot(ax=ax, color='red', markersize=5, alpha=0.7)\n",
    "plt.title(\"Intervention Points and Filtered Area\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cardiac_interventions = filtered_cardiac_interventions.drop(columns=['mission_id', 'postalcode_permanence', 'cityname_permanence',\n",
    "                                                                              'streetname_permanence', 'latitude_permanence', 'longitude_permanence',\n",
    "                                                                              'vector_type', 'name_destination_hospital', 'abandon_reason', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns to the desired format\n",
    "def format_datetime(dt_value):\n",
    "        if pd.isna(dt_value) or dt_value == '':\n",
    "            return np.nan\n",
    "        try:\n",
    "            # Parse the datetime string and reformat it\n",
    "            return pd.to_datetime(dt_value).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except:\n",
    "            # Return original value if conversion fails\n",
    "            return dt_value\n",
    "\n",
    "filtered_cardiac_interventions['t0'] = filtered_cardiac_interventions['t0'].apply(format_datetime)\n",
    "filtered_cardiac_interventions['t3'] = filtered_cardiac_interventions['t3'].apply(format_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, this doesn't work...\n",
    "# from datetime import datetime\n",
    "# def format_custom_datetime(dt_value):\n",
    "#         if pd.isna(dt_value) or dt_value == '':\n",
    "#             return np.nan\n",
    "#         # Parse using datetime.strptime with the specific format\n",
    "#         # The format is: DDMMMYY:HH:MM:SS (01JUN22:10:27:09)\n",
    "#         parsed_date = datetime.strptime(dt_value, '%d%b%y:%H:%M:%S')\n",
    "        \n",
    "#         # Convert to the desired format\n",
    "#         return parsed_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "# filtered_cardiac_interventions['t1'] = filtered_cardiac_interventions['t1'].apply(format_custom_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time between call and ambulance arrival (in minutes)\n",
    "# Convert to datetime\n",
    "filtered_cardiac_interventions['t3'] = pd.to_datetime(filtered_cardiac_interventions['t3'], errors='coerce')\n",
    "filtered_cardiac_interventions['t0'] = pd.to_datetime(filtered_cardiac_interventions['t0'], errors='coerce')\n",
    "\n",
    "# Function to calculate time difference (in seconds) based on alternative columns\n",
    "def calculate_time_difference(row):\n",
    "    if pd.isna(row['t3']) or pd.isna(row['t0']):\n",
    "        # Use alternative columns if t3 or t0 is missing\n",
    "        return (row['intervention_time_t3t1'] + row['departure_time_t1t0']) * 60\n",
    "    else:\n",
    "        # Calculate time difference based on t3 and t0\n",
    "        return (row['t3'] - row['t0']).total_seconds()\n",
    "\n",
    "# Apply the function to create the new column\n",
    "filtered_cardiac_interventions['t3t0_diff'] = filtered_cardiac_interventions.apply(calculate_time_difference, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cardiac_interventions.to_excel(\"filtered_cardiac_interventions.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_smart_duplicates(df):\n",
    "    # Make a copy of the original dataframe \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Create a composite key from latitude and longitude\n",
    "    df_copy['location_key'] = df_copy['latitude_intervention'].astype(str) + '_' + df_copy['longitude_intervention'].astype(str)\n",
    "    \n",
    "    # Create a score based on data completeness in t0 and t3\n",
    "    # A row gets +1 for each non-null value in these columns\n",
    "    df_copy['completeness_score'] = (\n",
    "        df_copy['t0'].notna().astype(int) + \n",
    "        df_copy['t3'].notna().astype(int)\n",
    "    )\n",
    "    \n",
    "    # Sort by completeness score in descending order\n",
    "    # This ensures rows with more data appear first\n",
    "    df_copy = df_copy.sort_values('completeness_score', ascending=False)\n",
    "    \n",
    "    # Keep the first occurrence of each location_key (which will be the most complete one)\n",
    "    df_deduplicated = df_copy.drop_duplicates(subset=['location_key'])\n",
    "    \n",
    "    # Drop the temporary columns we created\n",
    "    df_deduplicated = df_deduplicated.drop(columns=['location_key', 'completeness_score'])\n",
    "    \n",
    "    return df_deduplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_smart_duplicates_by_eventtype(df):\n",
    "    # Create an empty dataframe to store the results\n",
    "    result_df = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # Get unique event types\n",
    "    event_types = df['eventtype'].unique()\n",
    "    \n",
    "    # Process each event type separately\n",
    "    for event_type in event_types:\n",
    "        # Get the subset of data for this event type\n",
    "        event_df = df[df['eventtype'] == event_type].copy()\n",
    "        \n",
    "        # Create a composite key from latitude and longitude\n",
    "        event_df['location_key'] = event_df['latitude_intervention'].astype(str) + '_' + event_df['longitude_intervention'].astype(str)\n",
    "        \n",
    "        # Create a score based on data completeness in t0 and t3\n",
    "        # A row gets +1 for each non-null value in these columns\n",
    "        event_df['completeness_score'] = (\n",
    "            event_df['t0'].notna().astype(int) + \n",
    "            event_df['t3'].notna().astype(int)\n",
    "        )\n",
    "        \n",
    "        # Sort by completeness score in descending order\n",
    "        # This ensures rows with more data appear first\n",
    "        event_df = event_df.sort_values('completeness_score', ascending=False)\n",
    "        \n",
    "        # Keep the first occurrence of each location_key within this event type\n",
    "        event_df_deduplicated = event_df.drop_duplicates(subset=['location_key'])\n",
    "        \n",
    "        # Drop the temporary columns we created\n",
    "        event_df_deduplicated = event_df_deduplicated.drop(columns=['location_key', 'completeness_score'])\n",
    "        \n",
    "        # Append to the result dataframe\n",
    "        result_df = pd.concat([result_df, event_df_deduplicated], ignore_index=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cardiac_interventions_clean = remove_smart_duplicates(filtered_cardiac_interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cardiac_interventions_clean.to_excel(\"interventions_new.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cad9.to_excel(\"cad9.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
